{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erberry/ThinkML/blob/main/%E8%BF%90%E8%A1%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B_chatglm2_6b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFfIPDPEpz_v"
      },
      "source": [
        "### åœ¨ GPU ä¸Šæ¨ç†"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC9M9RIar0Vo"
      },
      "source": [
        "#### æŸ¥çœ‹å½“å‰ gpu ä¿¡æ¯\n",
        "\n",
        "colab çš„ T4 GPUå¯ä»¥å…è´¹ä½¿ç”¨ï¼Œæ˜¾å­˜ 16GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsKmy-WQrRX2",
        "outputId": "895675eb-7bc7-462c-acf1-1276ec31d8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jul  5 06:11:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgYbjTKBr4W-"
      },
      "source": [
        "#### ä¸‹è½½ ChatGLM2-6B ä»£ç ï¼Œå¹¶å®‰è£…ä¾èµ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHe2O0pzqDoc",
        "outputId": "30f9007c-0fb6-4b15-96f6-25c6a01fc16b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ChatGLM2-6B'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 175 (delta 64), reused 62 (delta 48), pack-reused 81\u001b[K\n",
            "Receiving objects: 100% (175/175), 5.09 MiB | 33.02 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/THUDM/ChatGLM2-6B.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1xEwuayqqhG"
      },
      "outputs": [],
      "source": [
        "!cd ChatGLM2-6B && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBkulOxr_3k"
      },
      "source": [
        "#### æ¨ç†\n",
        "\n",
        "é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆå¤§çº¦13GBï¼‰ï¼Œè€å¿ƒç­‰å¾…\n",
        "\n",
        "å¦‚æœæ˜¾å­˜æœ‰é™ï¼Œå¯ä»¥ä¿®æ”¹ cli_demo.py æ–‡ä»¶ï¼Œä½¿ç”¨é‡åŒ–æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š\n",
        "\n",
        "å°†\n",
        "\n",
        "```\n",
        "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True).cuda()\n",
        "```\n",
        "ä¿®æ”¹ä¸º\n",
        "\n",
        "```\n",
        "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True).quantize(8).cuda()\n",
        "```\n",
        "æˆ–è€…\n",
        "\n",
        "```\n",
        "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True).quantize(4).cuda()\n",
        "```\n",
        "\n",
        "é‡åŒ–æ¨¡å‹å°†æ¨¡å‹å‚æ•°ç²¾åº¦é™ä½ï¼Œä»¥å‡å°‘æ¨¡å‹å¯¹å†…å­˜çš„å ç”¨ï¼Œä½†ä¹Ÿä¼šä¼šé™ä½æ¨ç†å‡†ç¡®åº¦ã€‚\n",
        "\n",
        "å¦‚æœæ²¡æœ‰æ˜¾å¡ï¼Œå¯ä»¥ä½¿ç”¨ chatglm.cpp åœ¨CPUä¸Šæ¨ç†ï¼Œä½†æ˜¯æ¨ç†é€Ÿåº¦ä¼šæ¯”ä½¿ç”¨GPUæ…¢å¾ˆå¤šã€‚ åœ¨CPUä¸Šæ¨ç†è§ä¸‹æ–¹ ã€ä½¿ç”¨ chatglm.cpp åœ¨CPUä¸Šæ¨ç†ã€‘\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "epacu3-Irdov",
        "outputId": "3f9f2ad6-23d2-4656-d37b-0cd8e77ea928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-05 06:23:16.192149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading checkpoint shards: 100% 7/7 [01:08<00:00,  9.84s/it]\n",
            "æ¬¢è¿ä½¿ç”¨ ChatGLM2-6B æ¨¡å‹ï¼Œè¾“å…¥å†…å®¹å³å¯è¿›è¡Œå¯¹è¯ï¼Œclear æ¸…ç©ºå¯¹è¯å†å²ï¼Œstop ç»ˆæ­¢ç¨‹åº\n",
            "\n",
            "ç”¨æˆ·ï¼šæè¿°è“è‰²\n",
            "\n",
            "ChatGLMï¼šè“è‰²æ˜¯ä¸€ç§åŸºæœ¬é¢œè‰²,é€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¸€ç§å¹³é™ã€å†·é™å’Œä¿¡ä»»æ„Ÿå’Œå¹³é™çš„é¢œè‰²ã€‚è“è‰²ä¹Ÿä»£è¡¨ç€è®¸å¤šä¸åŒçš„æƒ…æ„Ÿ,ä¾‹å¦‚å¤©ç©ºã€æµ·æ´‹ã€æ¹–æ³Šã€è“è‰²ä»£è¡¨ä¿¡ä»»ã€ç¨³å®šã€æˆç†Ÿå’Œå®é™ç­‰ã€‚åœ¨ä¸åŒçš„æ–‡åŒ–å’Œä¼ ç»Ÿä¸­,è“è‰²ä¹Ÿå…·æœ‰ä¸åŒçš„è±¡å¾æ„ä¹‰ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼šç¿»è¯‘è¿™å¥è¯ â€œä½ å¥½ï¼Œè¯·é—®å¤©å®‰é—¨æ€ä¹ˆèµ°ï¼Ÿâ€œ åˆ°è‹±æ–‡\n",
            "\n",
            "ChatGLMï¼š\"ä½ å¥½,è¯·é—®å¤©å®‰é—¨æ€ä¹ˆèµ°?\" çš„è‹±æ–‡ç¿»è¯‘æ˜¯:\"Hello, how do you go to Tiananmen Square?\"\n",
            "\n",
            "ç”¨æˆ·ï¼šå†™ä¸€é¦–å…³äºçˆ±å¾—è¯—  \n",
            "\n",
            "ChatGLMï¼šçˆ±å¾—è¯—\n",
            "\n",
            "çˆ±,æ˜¯ç”Ÿå‘½ä¸­æœ€ç¾å¥½çš„æƒ…æ„Ÿ\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬å¿ƒçµé¢¤æŠ–\n",
            "è®©æˆ‘ä»¬æ„Ÿåˆ°å¹¸ç¦å’Œå……å®\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬çœ‹åˆ°ä¸–ç•Œçš„ç¾\n",
            "\n",
            "çˆ±,åƒæ˜¥é£æ‹‚é¢ä¸€æ ·æ¸©æš–\n",
            "å®ƒèƒ½æŠšæ‘¸æˆ‘ä»¬çš„çµé­‚\n",
            "è®©æˆ‘ä»¬æ„Ÿå—åˆ°ç”Ÿå‘½çš„æ„ä¹‰\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬çœ‹åˆ°æœªæ¥çš„å…‰æ˜\n",
            "\n",
            "çˆ±,åƒä¸€ç‰‡æ¹–æ°´ä¸€æ ·å¹³é™\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬å¿ƒçµå®é™\n",
            "è®©æˆ‘ä»¬æ„Ÿå—åˆ°å†…å¿ƒçš„åŠ›é‡\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬çœ‹åˆ°ç”Ÿå‘½çš„çœŸè°›\n",
            "\n",
            "çˆ±,åƒä¸€æœµé²œèŠ±ä¸€æ ·ç¾ä¸½\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬æ„Ÿå—åˆ°ç”Ÿå‘½çš„ç¾å¥½\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬æ„Ÿå—åˆ°ç”Ÿå‘½çš„æ¸©æš–\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬æ„Ÿå—åˆ°ç”Ÿå‘½çš„æ„ä¹‰\n",
            "\n",
            "çˆ±,æ˜¯ç”Ÿå‘½ä¸­æœ€ç¾å¥½çš„æƒ…æ„Ÿ\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬å¿ƒçµé¢¤æŠ–\n",
            "è®©æˆ‘ä»¬æ„Ÿåˆ°å¹¸ç¦å’Œå……å®\n",
            "å®ƒèƒ½è®©æˆ‘ä»¬çœ‹åˆ°ä¸–ç•Œçš„ç¾\n",
            "\n",
            "ç”¨æˆ·ï¼šè§£é‡Šé‡åŠ›å¾—æ¦‚å¿µ\n",
            "\n",
            "ChatGLMï¼šé‡åŠ›å¾—æ¦‚å¿µæ˜¯æŒ‡ç‰©ä½“ç”±äºåœ°çƒå¼•åŠ›çš„ä½œç”¨è€Œå—åˆ°çš„åŠ›ã€‚æ ¹æ®ç‰›é¡¿ç¬¬äºŒå®šå¾‹,ç‰©ä½“çš„åŠ é€Ÿåº¦ä¸ä½œç”¨åœ¨ç‰©ä½“ä¸Šçš„åŠ›æˆæ­£æ¯”,ä¸ç‰©ä½“çš„è´¨é‡æˆåæ¯”ã€‚å› æ­¤,å½“ä¸€ä¸ªç‰©ä½“åœ¨åœ°çƒä¸Šæ—¶,å®ƒå—åˆ°çš„é‡åŠ›ä½œç”¨äºå®ƒçš„è´¨é‡ä¸Š,å¯¼è‡´å®ƒäº§ç”ŸåŠ é€Ÿåº¦ã€‚é‡åŠ›çš„æ–¹å‘æ€»æ˜¯ç«–ç›´å‘ä¸‹çš„,å› æ­¤ç‰©ä½“ä¼šæ²¿ç€é‡åŠ›æ–¹å‘ä¸Šäº§ç”ŸåŠ é€Ÿåº¦ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼šè’™å¨œä¸½èæ˜¯è°ç”»çš„\n",
            "\n",
            "ChatGLMï¼šè’™å¨œä¸½è(Mona Lisa)æ˜¯ç”±æ„å¤§åˆ©è‰ºæœ¯å®¶è¾¾Â·èŠ¬å¥‡(Leonardo da Vinci)äº16ä¸–çºªæ—©æœŸç»˜åˆ¶çš„ä¸€å¹…è‚–åƒç”»ã€‚è¾¾Â·èŠ¬å¥‡æ˜¯æ–‡è‰ºå¤å…´æ—¶æœŸæœ€è‘—åçš„è‰ºæœ¯å®¶ä¹‹ä¸€,ä»–çš„ç»˜ç”»é£æ ¼å’ŒæŠ€èƒ½åœ¨ä»–æ‰€å¤„çš„æ—¶ä»£éå¸¸å—æ¬¢è¿,å¯¹åä¸–çš„è‰ºæœ¯å‘å±•äº§ç”Ÿäº†å·¨å¤§çš„å½±å“ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼šå¯¹64å¼€æ–¹\n",
            "\n",
            "ChatGLMï¼š64å¼€æ–¹æ˜¯æŒ‡64çš„ç®—æœ¯å¹³æ–¹æ ¹ã€‚ä¸€ä¸ªæ•°çš„ç®—æœ¯å¹³æ–¹æ ¹æ˜¯æŒ‡å¦ä¸€ä¸ªæ•°,å®ƒçš„å¹³æ–¹ç­‰äºåŸå§‹çš„æ•°ã€‚ä¾‹å¦‚,8çš„ç®—æœ¯å¹³æ–¹æ ¹æ˜¯2,å› ä¸º2çš„å¹³æ–¹ç­‰äº8ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼š64çš„å¹³æ–¹æ ¹\n",
            "\n",
            "ChatGLMï¼š64çš„å¹³æ–¹æ ¹æ˜¯8ã€‚æ ¹æ®å®šä¹‰,ä¸€ä¸ªæ•°çš„å¹³æ–¹æ ¹æ˜¯æŒ‡å¦ä¸€ä¸ªæ•°,å®ƒçš„å¹³æ–¹ç­‰äºåŸå§‹çš„æ•°ã€‚å› æ­¤,64çš„å¹³æ–¹æ ¹å°±æ˜¯ä¸€ä¸ªæ•°,å®ƒçš„å¹³æ–¹ç­‰äº64ã€‚å¯ä»¥ä½¿ç”¨è®¡ç®—å™¨æˆ–æ‰‹ç®—æ¥æ‰¾åˆ°64çš„å¹³æ–¹æ ¹,ç»“æœéƒ½æ˜¯8ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼šä½ èƒ½å”±ä¸€é¦–ã€Šæˆ‘çˆ±ä½ ä¸­å›½ã€‹å—\n",
            "\n",
            "ChatGLMï¼šæˆ‘ä¸èƒ½å”±ä¸€é¦–ã€Šæˆ‘çˆ±ä½ ä¸­å›½ã€‹ã€‚ä½œä¸ºä¸€ä¸ªè®¡ç®—æœºç¨‹åº,æˆ‘åªèƒ½é€šè¿‡æ–‡å­—äº¤æµæ¥è¡¨è¾¾æˆ‘çš„ä¿¡æ¯ã€‚æˆ‘ä¸èƒ½å”±æ­Œæˆ–æ¼”å¥ä¹å™¨ã€‚ä½†æ˜¯,æˆ‘å¯ä»¥é€šè¿‡æŸ¥è¯¢ç½‘ç»œæ¥æä¾›æœ‰å…³ã€Šæˆ‘çˆ±ä½ ä¸­å›½ã€‹çš„ä¿¡æ¯,è¿™æ˜¯ä¸€é¦–ç»å…¸çš„çˆ±å›½æ­Œæ›²ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼šè¯¦è¿°ä¸€ä¸‹å…‰åˆä½œç”¨çš„è¿‡ç¨‹\n",
            "\n",
            "ChatGLMï¼šå…‰åˆä½œç”¨æ˜¯æ¤ç‰©å’ŒæŸäº›ç»†èŒã€çœŸèŒç­‰ç”Ÿç‰©è¿›è¡Œè‡ªå…»çš„é‡è¦è¿‡ç¨‹ã€‚å®ƒæ˜¯åœ¨å…‰ç…§ä½œç”¨ä¸‹,åˆ©ç”¨å…‰èƒ½å°†äºŒæ°§åŒ–ç¢³å’Œæ°´è½¬åŒ–æˆå‚¨å­˜èƒ½é‡çš„æœ‰æœºç‰©,åŒæ—¶é‡Šæ”¾å‡ºæ°§æ°”çš„è¿‡ç¨‹ã€‚\n",
            "\n",
            "å…‰åˆä½œç”¨çš„è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µã€‚å…‰ååº”å’Œæš—ååº”ã€‚\n",
            "\n",
            "åœ¨å…‰ååº”ä¸­,å¶ç»¿ç´ å¸æ”¶å…‰èƒ½,å¹¶é€šè¿‡å…‰åŒ–å­¦ååº”å°†å…¶è½¬åŒ–ä¸ºåŒ–å­¦èƒ½ã€‚å…‰ååº”åŒ…æ‹¬ä¸¤ä¸ªååº”:å…‰ç³»ç»Ÿ I å’Œå…‰ç³»ç»Ÿ IIã€‚å…‰ç³»ç»Ÿ II åœ¨å…‰çº¿ä½œç”¨ä¸‹,å°†æ°´åˆ†å­åˆ†è§£ä¸ºæ°§æ°”å’Œç”µå­,åŒæ—¶äº§ç”Ÿ ATP å’Œ NADPH,è¿™äº›äº§ç‰©ä¸ºåç»­æš—ååº”æä¾›èƒ½é‡å’Œç”µå­ã€‚å…‰ç³»ç»Ÿ I åˆ™å°†å…‰èƒ½è½¬åŒ–ä¸ºç”µå­,ç»§ç»­äº§ç”Ÿ ATP å’Œ NADPHã€‚\n",
            "\n",
            "åœ¨æš—ååº”ä¸­,å›ºå®šäºŒæ°§åŒ–ç¢³å’Œæ°´,åˆæˆæœ‰æœºç‰©ã€‚æš—ååº”åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤:å›ºå®š CO2 å’Œè¿˜åŸ CO2ã€‚å›ºå®š CO2 çš„è¿‡ç¨‹åŒ…æ‹¬äºŒæ°§åŒ–ç¢³çš„å›ºå®šå’Œä¸‰ç¢³åŒ–åˆç‰©çš„è¿˜åŸã€‚ä¸‰ç¢³åŒ–åˆç‰©è¿˜åŸçš„è¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤:ä¸‰ç¢³åŒ–åˆç‰©è¿˜åŸä¸ºè‘¡è„ç³–æˆ–ç”˜æ²¹é†›ã€ä¸™é…®é…¸ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ\n",
            "\n",
            "ChatGLMï¼šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä¸€ä¸ªéå¸¸æŠ½è±¡çš„æ¦‚å¿µ,äººä»¬å¯¹å®ƒçš„çœ‹æ³•ä¸å°½ç›¸åŒã€‚å¯¹äºæŸäº›äººæ¥è¯´,ç”Ÿå‘½çš„æ„ä¹‰å¯èƒ½æ˜¯å®ç°è‡ªå·±çš„æ¢¦æƒ³,å¯¹äºå…¶ä»–äººæ¥è¯´,ç”Ÿå‘½çš„æ„ä¹‰å¯èƒ½æ˜¯ä¸ºäº†å®¶äººå’Œç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚å¯¹äºä¸€äº›äººæ¥è¯´,ç”Ÿå‘½çš„æ„ä¹‰å¯èƒ½æ˜¯é€šè¿‡å®—æ•™ä¿¡ä»°æ¥å¯»æ‰¾çš„ã€‚ç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä¸€ä¸ªéå¸¸å¤æ‚ä¸”ä¸ªäººåŒ–çš„æ¦‚å¿µ,äººä»¬å¯¹å®ƒçš„çœ‹æ³•ä¸å°½ç›¸åŒã€‚\n",
            "\n",
            "ï¿½è¿™äº›é™ˆè¿°ä¸­å¾—å‡ºä»€ä¹ˆç»“è®ºï¼Ÿ\n",
            "\n",
            "ChatGLMï¼šå¦‚æœæ‰€æœ‰çš„çŒ«éƒ½æ˜¯åŠ¨ç‰©,è€Œä¸”ä¸€äº›åŠ¨ç‰©æ˜¯ç‹—,é‚£ä¹ˆå¯ä»¥å¾—å‡ºç»“è®º:çŒ«å’Œç‹—éƒ½æ˜¯åŠ¨ç‰©ã€‚è¿™ä¸ªç»“è®ºå¯ä»¥ä»ä¸¤ä¸ªæ–¹é¢æ¥ç†è§£:\n",
            "\n",
            "1. çŒ«å’Œç‹—éƒ½æ˜¯åŠ¨ç‰©,å®ƒä»¬å±äºä¸åŒçš„ç‰©ç§ã€‚çŒ«æ˜¯ä¸€ç§å“ºä¹³åŠ¨ç‰©,è€Œç‹—æ˜¯ä¸€ç§å“ºä¹³åŠ¨ç‰©ã€‚å®ƒä»¬åœ¨ç”Ÿç‰©å­¦åˆ†ç±»å­¦ä¸­å±äºä¸åŒçš„ç±»åˆ«ã€‚\n",
            "\n",
            "2. çŒ«å’Œç‹—éƒ½æ˜¯åŠ¨ç‰©,å®ƒä»¬å…·æœ‰ä¸€äº›å…±åŒçš„ç‰¹å¾ã€‚ä¾‹å¦‚,å®ƒä»¬éƒ½èƒ½å‘¼å¸,éƒ½èƒ½æ¶ˆåŒ–é£Ÿç‰©,éƒ½èƒ½è¿åŠ¨ç­‰ã€‚\n",
            "\n",
            "ç”¨æˆ·ï¼š"
          ]
        }
      ],
      "source": [
        "!cd ChatGLM2-6B && python cli_demo.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4StL7U1YfnN"
      },
      "source": [
        "### ä½¿ç”¨ chatglm.cpp åœ¨CPUä¸Šæ¨ç†\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_bdg6fgYn33"
      },
      "source": [
        "#### ä¸‹è½½ ChatGLM2-6B å’Œ chatglm.cpp ä»£ç ï¼Œå¹¶å®‰è£…ä¾èµ–çš„ python åŒ…ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OBqqpGFW7rz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/THUDM/ChatGLM2-6B.git\n",
        "!cd ChatGLM2-6B && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vYi-VWxXFKy",
        "outputId": "d11c6c08-8b5b-497f-d775-ec93e34316be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'chatglm.cpp'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/36)\u001b[K\rremote: Counting objects:   5% (2/36)\u001b[K\rremote: Counting objects:   8% (3/36)\u001b[K\rremote: Counting objects:  11% (4/36)\u001b[K\rremote: Counting objects:  13% (5/36)\u001b[K\rremote: Counting objects:  16% (6/36)\u001b[K\rremote: Counting objects:  19% (7/36)\u001b[K\rremote: Counting objects:  22% (8/36)\u001b[K\rremote: Counting objects:  25% (9/36)\u001b[K\rremote: Counting objects:  27% (10/36)\u001b[K\rremote: Counting objects:  30% (11/36)\u001b[K\rremote: Counting objects:  33% (12/36)\u001b[K\rremote: Counting objects:  36% (13/36)\u001b[K\rremote: Counting objects:  38% (14/36)\u001b[K\rremote: Counting objects:  41% (15/36)\u001b[K\rremote: Counting objects:  44% (16/36)\u001b[K\rremote: Counting objects:  47% (17/36)\u001b[K\rremote: Counting objects:  50% (18/36)\u001b[K\rremote: Counting objects:  52% (19/36)\u001b[K\rremote: Counting objects:  55% (20/36)\u001b[K\rremote: Counting objects:  58% (21/36)\u001b[K\rremote: Counting objects:  61% (22/36)\u001b[K\rremote: Counting objects:  63% (23/36)\u001b[K\rremote: Counting objects:  66% (24/36)\u001b[K\rremote: Counting objects:  69% (25/36)\u001b[K\rremote: Counting objects:  72% (26/36)\u001b[K\rremote: Counting objects:  75% (27/36)\u001b[K\rremote: Counting objects:  77% (28/36)\u001b[K\rremote: Counting objects:  80% (29/36)\u001b[K\rremote: Counting objects:  83% (30/36)\u001b[K\rremote: Counting objects:  86% (31/36)\u001b[K\rremote: Counting objects:  88% (32/36)\u001b[K\rremote: Counting objects:  91% (33/36)\u001b[K\rremote: Counting objects:  94% (34/36)\u001b[K\rremote: Counting objects:  97% (35/36)\u001b[K\rremote: Counting objects: 100% (36/36)\u001b[K\rremote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects:   4% (1/23)\u001b[K\rremote: Compressing objects:   8% (2/23)\u001b[K\rremote: Compressing objects:  13% (3/23)\u001b[K\rremote: Compressing objects:  17% (4/23)\u001b[K\rremote: Compressing objects:  21% (5/23)\u001b[K\rremote: Compressing objects:  26% (6/23)\u001b[K\rremote: Compressing objects:  30% (7/23)\u001b[K\rremote: Compressing objects:  34% (8/23)\u001b[K\rremote: Compressing objects:  39% (9/23)\u001b[K\rremote: Compressing objects:  43% (10/23)\u001b[K\rremote: Compressing objects:  47% (11/23)\u001b[K\rremote: Compressing objects:  52% (12/23)\u001b[K\rremote: Compressing objects:  56% (13/23)\u001b[K\rremote: Compressing objects:  60% (14/23)\u001b[K\rremote: Compressing objects:  65% (15/23)\u001b[K\rremote: Compressing objects:  69% (16/23)\u001b[K\rremote: Compressing objects:  73% (17/23)\u001b[K\rremote: Compressing objects:  78% (18/23)\u001b[K\rremote: Compressing objects:  82% (19/23)\u001b[K\rremote: Compressing objects:  86% (20/23)\u001b[K\rremote: Compressing objects:  91% (21/23)\u001b[K\rremote: Compressing objects:  95% (22/23)\u001b[K\rremote: Compressing objects: 100% (23/23)\u001b[K\rremote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "Receiving objects:   0% (1/125)\rReceiving objects:   1% (2/125)\rReceiving objects:   2% (3/125)\rReceiving objects:   3% (4/125)\rReceiving objects:   4% (5/125)\rReceiving objects:   5% (7/125)\rReceiving objects:   6% (8/125)\rReceiving objects:   7% (9/125)\rReceiving objects:   8% (10/125)\rReceiving objects:   9% (12/125)\rReceiving objects:  10% (13/125)\rReceiving objects:  11% (14/125)\rReceiving objects:  12% (15/125)\rReceiving objects:  13% (17/125)\rReceiving objects:  14% (18/125)\rReceiving objects:  15% (19/125)\rReceiving objects:  16% (20/125)\rReceiving objects:  17% (22/125)\rReceiving objects:  18% (23/125)\rReceiving objects:  19% (24/125)\rReceiving objects:  20% (25/125)\rReceiving objects:  21% (27/125)\rReceiving objects:  22% (28/125)\rReceiving objects:  23% (29/125)\rReceiving objects:  24% (30/125)\rReceiving objects:  25% (32/125)\rReceiving objects:  26% (33/125)\rReceiving objects:  27% (34/125)\rReceiving objects:  28% (35/125)\rReceiving objects:  29% (37/125)\rReceiving objects:  30% (38/125)\rReceiving objects:  31% (39/125)\rReceiving objects:  32% (40/125)\rReceiving objects:  33% (42/125)\rReceiving objects:  34% (43/125)\rReceiving objects:  35% (44/125)\rReceiving objects:  36% (45/125)\rReceiving objects:  37% (47/125)\rReceiving objects:  38% (48/125)\rReceiving objects:  39% (49/125)\rReceiving objects:  40% (50/125)\rReceiving objects:  41% (52/125)\rReceiving objects:  42% (53/125)\rReceiving objects:  43% (54/125)\rReceiving objects:  44% (55/125)\rReceiving objects:  45% (57/125)\rReceiving objects:  46% (58/125)\rReceiving objects:  47% (59/125)\rReceiving objects:  48% (60/125)\rReceiving objects:  49% (62/125)\rReceiving objects:  50% (63/125)\rReceiving objects:  51% (64/125)\rReceiving objects:  52% (65/125)\rReceiving objects:  53% (67/125)\rReceiving objects:  54% (68/125)\rReceiving objects:  55% (69/125)\rReceiving objects:  56% (70/125)\rReceiving objects:  57% (72/125)\rReceiving objects:  58% (73/125)\rReceiving objects:  59% (74/125)\rReceiving objects:  60% (75/125)\rReceiving objects:  61% (77/125)\rReceiving objects:  62% (78/125)\rReceiving objects:  63% (79/125)\rReceiving objects:  64% (80/125)\rremote: Total 125 (delta 22), reused 19 (delta 13), pack-reused 89\u001b[K\n",
            "Receiving objects:  65% (82/125)\rReceiving objects:  66% (83/125)\rReceiving objects:  67% (84/125)\rReceiving objects:  68% (85/125)\rReceiving objects:  69% (87/125)\rReceiving objects:  70% (88/125)\rReceiving objects:  71% (89/125)\rReceiving objects:  72% (90/125)\rReceiving objects:  73% (92/125)\rReceiving objects:  74% (93/125)\rReceiving objects:  75% (94/125)\rReceiving objects:  76% (95/125)\rReceiving objects:  77% (97/125)\rReceiving objects:  78% (98/125)\rReceiving objects:  79% (99/125)\rReceiving objects:  80% (100/125)\rReceiving objects:  81% (102/125)\rReceiving objects:  82% (103/125)\rReceiving objects:  83% (104/125)\rReceiving objects:  84% (105/125)\rReceiving objects:  85% (107/125)\rReceiving objects:  86% (108/125)\rReceiving objects:  87% (109/125)\rReceiving objects:  88% (110/125)\rReceiving objects:  89% (112/125)\rReceiving objects:  90% (113/125)\rReceiving objects:  91% (114/125)\rReceiving objects:  92% (115/125)\rReceiving objects:  93% (117/125)\rReceiving objects:  94% (118/125)\rReceiving objects:  95% (119/125)\rReceiving objects:  96% (120/125)\rReceiving objects:  97% (122/125)\rReceiving objects:  98% (123/125)\rReceiving objects:  99% (124/125)\rReceiving objects: 100% (125/125)\rReceiving objects: 100% (125/125), 783.87 KiB | 13.06 MiB/s, done.\n",
            "Resolving deltas:   0% (0/60)\rResolving deltas:   3% (2/60)\rResolving deltas:   6% (4/60)\rResolving deltas:   8% (5/60)\rResolving deltas:  13% (8/60)\rResolving deltas:  18% (11/60)\rResolving deltas:  25% (15/60)\rResolving deltas:  26% (16/60)\rResolving deltas:  31% (19/60)\rResolving deltas:  36% (22/60)\rResolving deltas:  40% (24/60)\rResolving deltas:  41% (25/60)\rResolving deltas:  43% (26/60)\rResolving deltas:  45% (27/60)\rResolving deltas:  55% (33/60)\rResolving deltas:  56% (34/60)\rResolving deltas:  58% (35/60)\rResolving deltas:  60% (36/60)\rResolving deltas:  61% (37/60)\rResolving deltas:  71% (43/60)\rResolving deltas:  81% (49/60)\rResolving deltas:  90% (54/60)\rResolving deltas:  91% (55/60)\rResolving deltas:  96% (58/60)\rResolving deltas: 100% (60/60)\rResolving deltas: 100% (60/60), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/li-plus/chatglm.cpp.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giY455v5ZQHt"
      },
      "source": [
        "#### å¯¹åŸæ¨¡å‹è¿›è¡Œé‡åŒ–ã€‚å¯é€‰çš„é‡åŒ–ç±»å‹å¦‚ä¸‹ï¼š\n",
        "\n",
        "- q4_0: 4-bit integer quantization with fp16 scales.\n",
        "- q4_1: 4-bit integer quantization with fp16 scales and minimum values.\n",
        "- q5_0: 5-bit integer quantization with fp16 scales.\n",
        "- q5_1: 5-bit integer quantization with fp16 scales and minimum values.\n",
        "- q8_0: 8-bit integer quantization with fp16 scales.\n",
        "- f16: half precision floating point weights without quantization.\n",
        "- f32: single precision floating point weights without quantization.\n",
        "\n",
        "ä»¥ä¸Šç±»å‹ä»£è¡¨äº†æ¨¡å‹å‚æ•°çš„ç²¾åº¦ï¼Œç²¾åº¦è¶Šé«˜ï¼Œæ¨¡å‹æ¨ç†æ‰€éœ€è¦çš„å†…å­˜ç©ºé—´è¶Šå¤§ï¼Œæ¨ç†è¶Šå‡†ç¡®ã€‚åä¹‹é™ä½ç²¾åº¦å¯ä»¥é™ä½å¯¹å†…å­˜å¤§å°çš„è¦æ±‚ï¼Œä½†ä¹Ÿä¼šå½±å“æ¨ç†çš„å‡†ç¡®æ€§ã€‚\n",
        "\n",
        "è¿™é‡Œé€‰æ‹© f16ã€‚å¤§çº¦éœ€è¦13GBå†…å­˜ã€‚\n",
        "\n",
        "ç”±äºéœ€è¦ä¸‹è½½åŸæ¨¡å‹ï¼ˆå¤§çº¦16GBï¼‰ï¼Œæ‰§è¡Œæ¯”è¾ƒæ…¢ã€‚è€å¿ƒç­‰å¾…ï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFeCKG5DXVUe"
      },
      "outputs": [],
      "source": [
        "!cd chatglm.cpp && python3 convert.py -i THUDM/chatglm2-6b -t f16 -o chatglm2-ggml-f16.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Rh0gaKozWU"
      },
      "source": [
        "#### ç¼–è¯‘ chatglm.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sogv8N0yXemC"
      },
      "outputs": [],
      "source": [
        "!cd chatglm.cpp && cmake -B build && cmake --build build -j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2GsjWSZnXEA"
      },
      "source": [
        "#### å¼€å§‹æ¨ç†ã€‚\n",
        "\n",
        "-i å‚æ•°å¼€å¯äº¤äº’æ¨¡å¼ï¼Œå…¶ä»–å‚æ•° -h æŸ¥çœ‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5VujDhWYBwT",
        "outputId": "0a18f792-3d90-438d-8349-056af22f2d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ________          __  ________    __  ___                 \n",
            "   / ____/ /_  ____ _/ /_/ ____/ /   /  |/  /_________  ____  \n",
            "  / /   / __ \\/ __ `/ __/ / __/ /   / /|_/ // ___/ __ \\/ __ \\ \n",
            " / /___/ / / / /_/ / /_/ /_/ / /___/ /  / // /__/ /_/ / /_/ / \n",
            " \\____/_/ /_/\\__,_/\\__/\\____/_____/_/  /_(_)___/ .___/ .___/  \n",
            "                                              /_/   /_/       \n",
            "Prompt   > ä½ å¥½\n",
            "ChatGLM2 > ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM2-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n",
            "Prompt   > ä½ èƒ½å”±ä¸€é¦–ã€Šæˆ‘çˆ±ä½ ä¸­å›½ã€‹å—\n",
            "ChatGLM2 > æŠ±æ­‰ï¼Œä½œä¸ºäººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œæˆ‘ä¸å…·æœ‰å”±æ­Œçš„åŠŸèƒ½ã€‚ä½†æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ã€Šæˆ‘çˆ±ä½ ä¸­å›½ã€‹æ­Œè¯ã€‚\n",
            "\n",
            "ã€Šæˆ‘çˆ±ä½ ä¸­å›½ã€‹\n",
            "\n",
            "ä½œè¯ï¼šä¹”ç¾½\n",
            "ä½œæ›²ï¼šåˆ˜ç‚½\n",
            "\n",
            "ä¸€åƒé‡Œé€é¹…æ¯›ï¼Œ\n",
            "ç¤¼é€é»„æ²³å²¸ã€‚\n",
            "\n",
            "ä¹ç™¾ä¹åä¹é“å¼¯ï¼Œ\n",
            "ç•™ä¸‹ä¸¹å¿ƒä¸€ç‰‡ã€‚\n",
            "\n",
            "èƒ¸æ€€ type-script }\n",
            "\n",
            "â‘¡æ€ªå·¥ä½œæ•ˆç‡ä½ï¼Œ\n",
            "ä½¿äººç´¯å¾—é€ä¸è¿‡æ°”ã€‚\n",
            "Prompt   > è¯¦è¿°ä¸€ä¸‹å…‰åˆä½œç”¨çš„è¿‡ç¨‹\n",
            "ChatGLM2 > å…‰åˆä½œç”¨æ˜¯æ¤ç‰©å’ŒæŸäº›å¾®ç”Ÿç‰©åˆ©ç”¨å…‰èƒ½å°†äºŒæ°§åŒ–ç¢³å’Œæ°´åˆæˆæœ‰æœºç‰©ï¼ŒåŒæ—¶é‡Šæ”¾æ°§æ°”çš„è¿‡ç¨‹ã€‚å®ƒå‘ç”Ÿåœ¨æ¤ç‰©ç»†èƒçš„å¶ç»¿ä½“ä¸­ï¼Œæ˜¯ä¸€ç§é‡è¦çš„ç”Ÿå‘½æ´»åŠ¨ã€‚å…‰åˆä½œç”¨çš„è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šå…‰ååº”å’Œæš—ååº”ã€‚\n",
            "\n",
            "å…‰ååº”é˜¶æ®µåœ¨å…‰ç…§ä¸‹è¿›è¡Œï¼Œä¸»è¦è´Ÿè´£å¸æ”¶å…‰èƒ½å¹¶å°†å…¶è½¬åŒ–ä¸ºåŒ–å­¦èƒ½ã€‚è¯¥è¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤ï¼šå…‰ç³»ç»Ÿ I å’Œå…‰ç³»ç»Ÿ IIã€‚\n",
            "\n",
            "1. å…‰ç³»ç»Ÿ IIï¼šåˆç§°å¶ç»¿ç´ å…‰ç³»ç»Ÿï¼Œè´Ÿè´£å¸æ”¶å…‰èƒ½ã€‚å®ƒåŒ…æ‹¬ä¸€ä¸ªç‰¹æ®Šçš„å¶ç»¿ç´ åˆ†å­ï¼Œç§°ä¸ºå¶ç»¿ç´  aï¼Œè¿˜æœ‰ä¸€ä¸ªè¾…åŠ©è‰²ç´ â€”â€”å¶ç»¿ç´  bã€‚å½“å…‰å­ç…§å°„åˆ°å¶ç»¿ç´  a æ—¶ï¼Œå¶ç»¿ç´  a çš„ä¸€ä¸ªç”µå­è¢«å…‰å­æ¿€å‘ï¼Œå½¢æˆä¸€ä¸ªé«˜èƒ½ç”µå­ã€‚è¿™ä¸ªé«˜èƒ½ç”µå­éšåæ’\n",
            "Prompt   > ç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ\n",
            "ChatGLM2 > ç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä¸€ä¸ªéå¸¸æ·±åˆ»å’Œå“²å­¦æ€§çš„é—®é¢˜ï¼Œæ²¡åŠæ³•ç”¨ä¸‰è¨€ä¸¤è¯­æ¥å›ç­”ã€‚æ¯ä¸ªäººå¯¹ç”Ÿå‘½çš„æ„ä¹‰éƒ½æœ‰è‡ªå·±çš„çœ‹æ³•å’Œå®šä¹‰ã€‚\n",
            "\n",
            "ä»ç”Ÿç‰©å­¦çš„è§’åº¦æ¥çœ‹ï¼Œç”Ÿå‘½çš„æ„ä¹‰æ˜¯ç»†èƒå¢æ®–ã€é—ä¼ å’Œç¹è¡ã€‚æ¯ä¸ªç”Ÿç‰©éƒ½æœ‰ä¸€ä¸ªåŸºæœ¬çš„æœ¬èƒ½ï¼Œé‚£å°±æ˜¯ç”Ÿå­˜ä¸‹å»å¹¶æŠŠè‡ªå·±çš„åŸºå› ä¼ é€’ç»™ä¸‹ä¸€ä»£ã€‚ç»†èƒå¢æ®–ã€é—ä¼ å’Œç¹è¡æ˜¯ç”Ÿç‰©å­˜åœ¨å’Œç¹è¡çš„åŸºç¡€ã€‚\n",
            "\n",
            "ä»å“²å­¦çš„è§’åº¦æ¥çœ‹ï¼Œç”Ÿå‘½çš„æ„ä¹‰åœ¨äºè¿½æ±‚å¹¸ç¦ã€å¯»æ‰¾çœŸç†ã€å®ç°ç²¾ç¥ä¸Šçš„æ»¡è¶³ã€‚åœ¨äººç±»ä¸­ï¼Œç”Ÿå‘½çš„æ„ä¹‰è¿˜åœ¨äºè¿½æ±‚è‡ªç”±ã€å¹³ç­‰å’Œå°Šä¸¥ã€‚\n",
            "\n",
            "ç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼Œæ²¡åŠæ³•ç”¨ä¸‰è¨€ä¸¤è¯­æ¥å›ç­”ã€‚æ¯ä¸ªäººéƒ½éœ€è¦è‡ªå·±æ€è€ƒå’Œå¯»æ‰¾è‡ªå·±ç”Ÿå‘½çš„æ„ä¹‰ã€‚\n",
            "Prompt   > ^C\n"
          ]
        }
      ],
      "source": [
        "!cd chatglm.cpp && ./build/bin/main -m chatglm2-ggml-f16.bin -i"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNkSSiFGKzi9osmho6vqs7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}